import streamlit as st
import random
from streamlit_pdf_viewer import pdf_viewer
from PyPDF2 import PdfReader
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.chains import ReduceDocumentsChain,StuffDocumentsChain
from langchain_community.document_loaders import PyPDFLoader
from langchain_openai import ChatOpenAI
from langchain.docstore.document import Document
from langchain.text_splitter import CharacterTextSplitter
from langchain.chains.summarize import load_summarize_chain
import os
from dotenv import load_dotenv, find_dotenv
from logic import readPdfToDocumentList,cache_add_file,get_File_by_name,CFile,cache_clear_file
from css import css
import copy
from typing import  List
load_dotenv(find_dotenv('.env'))
api_key = os.environ.get('openai_api_key')

model_name = 'gpt-3.5-turbo-ca'

llm = ChatOpenAI(temperature=0, model_name=model_name,
                 openai_api_base="https://api.chatanywhere.tech/v1",
                 openai_api_key=api_key
                 )

if 'file_document' not in st.session_state.keys():
    st.session_state['file_document']: List[CFile] = []



def page_layout_view():
    st.set_page_config(page_title="KnowledgeGPT", page_icon="ğŸ“–", layout="wide")
    st.header("ğŸ“–çŸ¥è¯†GPT")
    st.write(css, unsafe_allow_html=True)


def clear_docs():
    st.session_state.pop('key')
    st.session_state.pop('file_document')
    st.rerun()


def sidebar_view():
    with st.sidebar:
        st.success("åœ¨ä¸Šæ–¹é€‰æ‹©ä¸€ä¸ªé¡µé¢ã€‚")
        st.write("æ–‡ä»¶ä¸Šä¼ ")
        if 'key' not in st.session_state: st.session_state.key = str(random.randint(1000, 100000000))
        uploaded_files = st.file_uploader(
            "Upload a pdf, docx, or txt file",
            type=["pdf", "docx", "txt"],
            help="Scanned documents are not supported yet!",
            accept_multiple_files=True,
            label_visibility="collapsed",
            key = st.session_state.key
        )

        is_clear_docs = st.button("æ¸…ç©ºæ–‡æ¡£", type="primary")
        upload_file = None
        if uploaded_files:
            select_paper = st.selectbox('é€‰æ‹©æ–‡ç« ',
                                         [""]+[file.name for file in uploaded_files])
            cache_clear_file(uploaded_files)
            for file in uploaded_files:
                if get_File_by_name(file.name) is None:
                    doc_list = readPdfToDocumentList(copy.deepcopy(file))
                    cFile = CFile(file.name,file.read(),doc_list)
                    cache_add_file(cFile)

            if select_paper:
                upload_file = select_paper

        if is_clear_docs and 'key' in st.session_state.keys():
            clear_docs()

        return upload_file


def content_container(pdf_file_name):
    if pdf_file_name:
        file = get_File_by_name(pdf_file_name)
        import base64
        base64_pdf = base64.b64encode(file.pdf_show_content).decode('utf-8')
        pdf_display = f'<embed src="data:application/pdf;base64,{base64_pdf}" width="98%" height="1000" type="application/pdf">'
        st.markdown(pdf_display, unsafe_allow_html=True)


def chat_container(pdf_file_name):
    if pdf_file_name:
        mission = st.selectbox(label="" ,options=['','æ€»ç»“æ–‡ç« ','åˆ—å‡ºå…³é”®ç‚¹'])
        file = get_File_by_name(pdf_file_name)
        docs = file.doc_list

        if mission == 'æ€»ç»“æ–‡ç« ':
            # Text summarization
            prompt = PromptTemplate(input_variables=['docs'],
                                    template=""""The following is a set of documents
                 {docs}
                 æ ¹æ®è¿™ä¸ªæ–‡æ¡£åˆ—è¡¨ï¼Œå†™ä¸€ä¸ª200å­—ä»¥å†…çš„æ‘˜è¦.
                 Helpful Answer:""")
            # Text summarization
            chain = LLMChain(llm=llm, prompt=prompt)#æ¯”chain = load_summarize_chain(llm, chain_type='map_reduce')æ›´å¿«ï¼Œæ¶ˆè€—çš„tokenä¹ŸåŸºæœ¬ä¸€æ ·ï¼Œä¸”åªéœ€è¦è°ƒç”¨ä¸€æ¬¡#ä¸chain = load_summarize_chain(llm, chain_type='stuff')ä¸€è‡´ï¼›è‡ªå·±åˆ›å»ºpromptçš„å¥½å¤„å°±æ˜¯å¯ä»¥è‡ªå®šä¹‰ï¼Œæ¨è
            content = chain.invoke(docs)
            st.write(content['text'])
            pass
        elif mission == "åˆ—å‡ºå…³é”®ç‚¹":
            prompt = PromptTemplate(input_variables=['docs'],
                                               template=""""The following is a set of documents
                {docs}
                æ ¹æ®è¿™ä¸ªæ–‡æ¡£åˆ—è¡¨ï¼Œåˆ—å‡ºåä¸ªæœ€é‡è¦çš„å…³é”®è¯
                Helpful Answer:""")
            # Text summarization
            chain = LLMChain(llm=llm, prompt=prompt)
            content = chain.invoke({"docs":docs})
            st.write(content['text'])


def main():

    page_layout_view()
    upload_file = sidebar_view()
    if upload_file is None: #å¤špdfé—®ç­”
        pass
    else: #å•ä¸ªpdfé—®ç­”
        col1, col2 = st.columns(2)
        with col1:
            content_container(upload_file)
        with col2:
            chat_container(upload_file)


main()


